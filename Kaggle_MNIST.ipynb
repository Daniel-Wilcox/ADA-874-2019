{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: MNIST Challenge\n",
    "## Coded by Daniel Wilcox\n",
    "\n",
    "This is a notebook showing the process in predicting hand written digits 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misc.\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import glob\n",
    "import re\n",
    "\n",
    "#Dataframs and Arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Graphics\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data Augmentation\n",
    "from scipy.ndimage.interpolation import shift, rotate, map_coordinates, zoom\n",
    "\n",
    "#Dataset manipulation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "#Classifier Models:\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Location of dataset (Train and Test data):\n",
    "MNIST_PATH = \"datasets/MNIST_Kaggle\"\n",
    "\n",
    "#The Location of saved models:\n",
    "MODEL_PATH = \"datasets/MNIST_Kaggle/Models\"\n",
    "\n",
    "#The Location of submission csv's:\n",
    "SUBMISSION_PATH = \"datasets/MNIST_Kaggle/Submissions\" \n",
    "\n",
    "#CSV titles of Train and Test data:\n",
    "train_name = \"train.csv\" \n",
    "test_name = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting MNIST data from csv files\n",
    "\n",
    "def load_MNIST_data(file_name, mnist_path=MNIST_PATH):\n",
    "    csv_path = os.path.join(mnist_path, file_name)\n",
    "    return pd.read_csv(csv_path)\n",
    "        \n",
    "    \n",
    "def get_MNIST_data(file_name, mnist_path=MNIST_PATH):\n",
    "    csv_path = os.path.join(mnist_path, file_name)\n",
    "    print(\"Checking if directory exists...\")\n",
    "    \n",
    "    if not os.path.isdir(mnist_path):\n",
    "        os.makedirs(mnist_path)\n",
    "        print(\"Creating directory\")\n",
    "    \n",
    "    else: \n",
    "        print(\"Directory exists\") \n",
    "            \n",
    "        if os.path.isfile(csv_path):\n",
    "            print(file_name + \" file does exists...\")\n",
    "            print(\"extracting \" + file_name)\n",
    "            mnist = load_MNIST_data(file_name)\n",
    "            print(\"\\nSuccess!\")\n",
    "            return mnist\n",
    "        \n",
    "        else:\n",
    "            print(file_name + \" file doesn't exists...\")\n",
    "            print(\"Download .csv from Kaggle!\")\n",
    "            return None\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display chosen digit:\n",
    "\n",
    "def plot_digits(X):\n",
    "    rand_digit = X\n",
    "    rand_digit_img = rand_digit.reshape(28, 28)\n",
    "    plt.imshow(rand_digit_img, cmap = matplotlib.cm.binary, \n",
    "           interpolation=\"nearest\")\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Graph reset:\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make .csv file\n",
    "def make_csv(csv_name, save_loc=SUBMISSION_PATH):\n",
    "    curr_path = os.getcwd()\n",
    "    save_path = os.path.join(curr_path, save_loc)\n",
    "    os.chdir(save_path)\n",
    "    \n",
    "    max_i = 0\n",
    "    len_name = len(csv_name)\n",
    "           \n",
    "    for file in glob.glob(csv_name+'*.csv'):\n",
    "        \n",
    "        file_name = file[:len(file)-4]\n",
    "        file_ver = file_name[len_name:]\n",
    "        \n",
    "        if int(file_ver) > max_i:\n",
    "            max_i = int(file_ver)\n",
    "        \n",
    "    new_ver = csv_name+str(max_i+1)+'.csv'\n",
    "    os.chdir(curr_path)\n",
    "    \n",
    "    return os.path.join(save_path, new_ver) \n",
    "\n",
    "\n",
    "def create_submission(prediction, name):\n",
    "    \n",
    "    \n",
    "    Submission = pd.DataFrame({'ImageId': np.arange(len(prediction))+1, \n",
    "                           'Label': prediction}) \n",
    "    \n",
    "    file_name = make_csv(name)\n",
    "\n",
    "    Submission.to_csv(file_name, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mac notification banner:\n",
    "def notify(title, text):\n",
    "    os.system(\"\"\"\n",
    "              osascript -e 'display notification \"{}\" with title \"{}\"'\n",
    "              \"\"\".format(text, title))\n",
    "    os.system('osascript -e \"beep 1\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if directory exists...\n",
      "Directory exists\n",
      "train.csv file does exists...\n",
      "extracting train.csv\n",
      "\n",
      "Success!\n",
      "Checking if directory exists...\n",
      "Directory exists\n",
      "test.csv file does exists...\n",
      "extracting test.csv\n",
      "\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "Train = get_MNIST_data(train_name)\n",
    "Test = get_MNIST_data(test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "Test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data:\n",
    "- Pandas Dataframe\n",
    "- 42000 entries\n",
    "- Each entry is 1 + 28x28: the numbers label and the numbers image pixels \n",
    "\n",
    "\n",
    "### Test Data:\n",
    "- Pandas Dataframe\n",
    "- 28000 entries\n",
    "- Each entry is 28x28: the numbers image pixels (no label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Training Data shape\":\n",
      "----------------------\n",
      "(42000, 784)\n",
      "\n",
      "\n",
      "\"Label's shape\":\n",
      "-----------------\n",
      "(42000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Separate labels from training data\n",
    "X_tr = Train.iloc[:, 1:].values\n",
    "y_tr = Train.iloc[:, :1].values\n",
    "test = Test.iloc[:, :].values\n",
    "\n",
    "\n",
    "print(\"\\\"Training Data shape\\\":\\n----------------------\\n{}\\n\".format(X_tr.shape))\n",
    "print(\"\\n\\\"Label's shape\\\":\\n-----------------\\n{}\\n\".format(y_tr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train Data:\n",
      "There are 0 null entires.\n",
      "\n",
      "For Test Data:\n",
      "There are 0 null entires.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def null_check(X):\n",
    "    check = X.isnull().sum().sum() #sum all col, sum all rows\n",
    "    print(\"There are {:.0f} null entires.\\n\".format(check))\n",
    "\n",
    "    \n",
    "print(\"For Train Data:\")\n",
    "null_check(Train)\n",
    "\n",
    "print(\"For Test Data:\")\n",
    "null_check(Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen number that is displayed is labeled as \"[6]\".\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(50)\n",
    "rand_num = random.randrange(0, len(X_tr))\n",
    "\n",
    "rand_digit = X_tr[rand_num]\n",
    "\n",
    "print(\"The chosen number that is displayed is labeled as \\\"{}\\\".\\n\".format(y_tr[rand_num]))\n",
    "\n",
    "plot_digits(rand_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([4132, 4684, 4177, 4351, 4072, 3795, 4137, 4401, 4063, 4188]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Add labels and title\n",
    "g = sns.countplot(y_tr[:,0])\n",
    "np.unique(y_tr, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/ndimage/interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shifter(img, dx, dy):\n",
    "    img = img.reshape(28, 28)\n",
    "    img_shift = shift(img, [dy, dx], mode=\"constant\", cval=0)\n",
    "    return img_shift.reshape([-1]) #returns 1xn array i.e. as the data is stored originally\n",
    "\n",
    "def rotater(img, angle):\n",
    "    img = img.reshape(28, 28)\n",
    "    img_rotate = rotate(img, angle, reshape=False, order=1, prefilter=False)\n",
    "    return img_rotate.reshape([-1])\n",
    "\n",
    "def vert_mirror(img):\n",
    "    img = img.reshape(28, 28)\n",
    "    img_flip = np.fliplr(img)\n",
    "    return img_flip.reshape([-1])\n",
    "\n",
    "def add_noise(img):\n",
    "    noise = np.random.randint(0, 100, (1, 784))\n",
    "    return (img + noise)#/255.0\n",
    "\n",
    "def zoomer(img, xy_zoom):\n",
    "    img = img.reshape(28, 28)\n",
    "    \n",
    "    h, w = img.shape[:2] #28, 28\n",
    "    zoom_tup = (xy_zoom, )*2 + (1, )*(img.ndim -2)\n",
    "    \n",
    "    zh = int(np.round(h/xy_zoom))  #23\n",
    "    zw = int(np.round(w/xy_zoom)) #23\n",
    "    top = (h - zh)//2  #5\n",
    "    left = (w - zw)//2 #5\n",
    "    \n",
    "    out = zoom(img[top:top+zh, left:left+zw], zoom_tup, mode=\"constant\")\n",
    "    trim_top = ((out.shape[0]-h)//2)\n",
    "    trim_left = ((out.shape[1]-w)//2)\n",
    "    \n",
    "    print(trim_top)\n",
    "    img_zoom = out[trim_top:trim_top+h, trim_left:trim_left+w].clip(min=0)\n",
    "    \n",
    "    return img_zoom.reshape([-1])\n",
    "    \n",
    "\n",
    "rot_img = rotater(X_tr[42], 25)\n",
    "shift_rgt = shifter(X_tr[42], 5, 0)\n",
    "img_zoom = zoomer(X_tr[42], 1.2)\n",
    "\n",
    "plot_digits(X_tr[42])\n",
    "plot_digits(rot_img)\n",
    "plot_digits(shift_rgt)\n",
    "plot_digits(img_zoom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_augmentation(X, y, add_percent, add_shift=True, add_rotate=True,\n",
    "                add_zoom=True):\n",
    "    \n",
    "    \n",
    "    aug_frac = int(round(len(X_tr)*add_percent))\n",
    "    X_add = X[:aug_frac]\n",
    "    y_add = y[:aug_frac]\n",
    "\n",
    "    #Random numbers:\n",
    "    #spliter = StratifiedShuffleSplit(n_splits=1, train_size=add_percent,\n",
    "     #                                    random_state=42)\n",
    "\n",
    "    \n",
    "    #for add_idx, ignore_idx in spliter.split(X, y):\n",
    "    #    X_add = X[add_idx]\n",
    "    #    y_add = y[add_idx]\n",
    "    \n",
    "    #so can ignore 0-X_add_len later\n",
    "    add_len = len(X_add) \n",
    "    expect_new = add_len * ((add_shift)+(add_rotate)+(add_zoom))\n",
    "    \n",
    "    j = 0\n",
    " \n",
    "    if add_shift:\n",
    "        #Shift image up/down/left/right by 5 pixels\n",
    "\n",
    "        for i in range(add_len): \n",
    "            rand = np.random.randint(4)\n",
    "            \n",
    "            if rand == 0:\n",
    "                y_add = np.vstack([y_add, y_add[i]]) \n",
    "                right = shifter(X_add[i], 5, 0)\n",
    "                X_add = np.vstack([X_add, right])\n",
    "             \n",
    "            if rand == 1:\n",
    "                y_add = np.vstack([y_add, y_add[i]])\n",
    "                left = shifter(X_add[i], -5, 0)\n",
    "                X_add = np.vstack([X_add, left])\n",
    "            \n",
    "            if rand == 2:\n",
    "                y_add = np.vstack([y_add, y_add[i]]) \n",
    "                up = shifter(X_add[i], 0, 5)\n",
    "                X_add = np.vstack([X_add, up])\n",
    "            \n",
    "            if rand == 3:\n",
    "                y_add = np.vstack([y_add, y_add[i]]) \n",
    "                down = shifter(X_add[i], 0, -5)\n",
    "                X_add = np.vstack([X_add, down])\n",
    "                \n",
    "            j = j + 1\n",
    "            sys.stdout.flush()\n",
    "            print(\"\\r{}%\".format(100 * j // expect_new), end=\"\")\n",
    "\n",
    "\n",
    "            \n",
    "    if add_rotate:\n",
    "        #rotate cw/ccw by 25 & 45 degrees \n",
    "                  \n",
    "        for i in range(add_len):\n",
    "               \n",
    "            rand = np.random.randint(4)\n",
    "            \n",
    "            if rand == 0:\n",
    "                y_add = np.vstack([y_add, y_add[i]]) \n",
    "                ccw25 = rotater(X_add[i], 25)\n",
    "                X_add = np.vstack([X_add, ccw25])\n",
    "                \n",
    "            if rand == 1:  \n",
    "                y_add = np.vstack([y_add, y_add[i]])\n",
    "                ccw45 = rotater(X_add[i], 45)\n",
    "                X_add = np.vstack([X_add, ccw45])\n",
    "                \n",
    "            if rand == 2:    \n",
    "                y_add = np.vstack([y_add, y_add[i]]) \n",
    "                cw25 = rotater(X_add[i], -25)\n",
    "                X_add = np.vstack([X_add, cw25])\n",
    "                \n",
    "            if rand == 3:\n",
    "                y_add = np.vstack([y_add, y_add[i]]) \n",
    "                cw45 = rotater(X_add[i], -45)\n",
    "                X_add = np.vstack([X_add, cw45])\n",
    "                  \n",
    "            j = j+1\n",
    "            sys.stdout.flush()\n",
    "            print(\"\\r{}%\".format(100 * j // expect_new), end=\"\")\n",
    "                  \n",
    "    if add_zoom:\n",
    "        #20% zoom\n",
    "        for i in range(add_len):\n",
    "            y_add = np.vstack([y_add, y_add[i]]) \n",
    "            zoomed = zoomer(X_add[i], 1.2)\n",
    "            X_add = np.vstack([X_add, zoomed])\n",
    "            j = j+1 \n",
    "            sys.stdout.flush()\n",
    "            print(\"\\r{}%\".format(100 * j // expect_new), end=\"\")\n",
    "\n",
    "                       \n",
    "    X = np.vstack([X, X_add[add_len:]])\n",
    "    y = np.vstack([y, y_add[add_len:]])\n",
    "    \n",
    "    shuffle_index = np.random.permutation(len(X))\n",
    "    X_Aug, y_Aug = X[shuffle_index], y[shuffle_index]\n",
    "    \n",
    "    notify('Kaggle:', 'Data Augmentation Complete')    \n",
    "    return X_Aug, y_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if directory exists...\n",
      "Directory exists\n",
      "Aug_all_Train.csv file does exists...\n",
      "extracting Aug_all_Train.csv\n",
      "\n",
      "Success!\n",
      "file exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(168000, 785)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only run if Augmented data hasn't been made yet:\n",
    "\n",
    "Aug_name = 'Aug_all_Train.csv'\n",
    "csv_path = os.path.join(MNIST_PATH, Aug_name)\n",
    "\n",
    "if os.path.isfile(csv_path):\n",
    "    Aug_train = get_MNIST_data(Aug_name)\n",
    "    print('file exists')\n",
    "else:\n",
    "    #print('file doesn\\'t exists, making .csv')\n",
    "    X_new, y_new = Data_augmentation(X_tr/255, y_tr, add_percent=1)\n",
    "    XX = np.hstack((y_new, X_new))\n",
    "    Aug_data = pd.DataFrame(XX)\n",
    "    Aug_data.to_csv(csv_path, index=False)\n",
    "    notify('Kaggle:', 'Data Augmentation csv creation Complete') \n",
    "    Aug_train = get_MNIST_data(Aug_name)\n",
    "    \n",
    "Aug_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Training set:\t168000 elements\n"
     ]
    }
   ],
   "source": [
    "X_tr = Aug_train.iloc[:, 1:].values\n",
    "y_tr = Aug_train.iloc[:, :1].values\n",
    "\n",
    "print(\"Augmented Training set:\\t{} elements\".format(len(X_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\t134400 elements\n",
      "Validation set:\t33600 elements\n"
     ]
    }
   ],
   "source": [
    "spliter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in spliter.split(X_tr, y_tr):\n",
    "    X_train = X_tr[train_idx]\n",
    "    y_train = y_tr[train_idx]\n",
    "    \n",
    "    X_val = X_tr[val_idx]\n",
    "    y_val = y_tr[val_idx]\n",
    "\n",
    "\n",
    "print(\"Training set:\\t{} elements\\nValidation set:\\t{} elements\".format(len(X_train),len(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape Data:\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28)#/255.0\n",
    "y_train = y_train.astype(np.int32).reshape(len(y_train), )\n",
    "\n",
    "X_val = X_val.astype(np.float32).reshape(-1, 28*28)#/255.0\n",
    "y_val = y_val.astype(np.int32).reshape(len(y_val), )\n",
    "\n",
    "test = test.astype(np.float32).reshape(-1, 28*28)#/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " array([16528, 18736, 16708, 17404, 16288, 15180, 16548, 17604, 16252,\n",
       "        16752]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Add labels and title\n",
    "g = sns.countplot(y_tr[:,0])\n",
    "np.unique(y_tr, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network's Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training batches:\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X)) #stratified\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "#Get model parameters:\n",
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "#Retreive model parameters:\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Layers: \n",
    "n_inputs = 28*28\n",
    "\n",
    "#conv layer 1:\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 5\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "#pooling layer 1:\n",
    "pool1_fmaps = conv1_fmaps\n",
    "pool1_ksize = 2\n",
    "pool1_stride = 2\n",
    "pool1_pad = \"SAME\"\n",
    "\n",
    "#conv layer 2:\n",
    "conv2_fmaps = 32#64\n",
    "conv2_ksize = 5\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "\n",
    "#pooling layer 2:\n",
    "pool2_fmaps = conv1_fmaps\n",
    "pool2_ksize = 2\n",
    "pool2_stride = 2\n",
    "pool2_pad = \"SAME\"\n",
    "pool2_dropout_rate = 0.25\n",
    "\n",
    "n_fc1 = 128\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make CNN Graph:\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "#output is 28x28*32\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "#output is 14x14*32\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                       padding=pool1_pad, name=\"pool1\")\n",
    "\n",
    "#output is 14x14*64\n",
    "conv2 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "#output is 7*7*64 -> \n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, conv2_fmaps * 7 * 7])\n",
    "    pool2_flat_drop = tf.layers.dropout(pool2_flat, pool2_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool2_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape Data:\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28)\n",
    "y_train = y_train.astype(np.int32).reshape(len(y_train), )\n",
    "\n",
    "X_val = X_val.astype(np.float32).reshape(-1, 28*28)\n",
    "y_val = y_val.astype(np.int32).reshape(len(y_val), )\n",
    "\n",
    "test = test.astype(np.float32).reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training batches:\n",
    "\n",
    "#----------------------------------change to stratified\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X)) #stratified\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "#Get model parameters:\n",
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "#Retreive model parameters:\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "iteration = 0\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            iteration += 1\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss.eval(feed_dict={X: X_val, y: y_val})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(\"Epoch {}, last batch accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                  epoch, acc_batch * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "        \n",
    "        \n",
    "    #insert Test prediciton:    \n",
    "    acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "    print(\"Final accuracy on Validation set:\", acc_val)\n",
    "    notify(\"MNIST_Kaggle\", \"Completed Submission of CNN\")\n",
    "    save_path = saver.save(sess, \"./my_mnist_cnn_model\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as tfs:\n",
    "    saver.restore(tfs, \"./my_mnist_cnn_model\")\n",
    "    \n",
    "    pred = logits.eval(feed_dict={X: test})\n",
    "    prediction = np.argmax(pred, 1)\n",
    "    \n",
    "    create_submission(prediction, \"Submission_\")\n",
    "    notify(\"MNIST_Kaggle\", \"Completed Submission of CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional Neural Network 2:\n",
    "based off:\n",
    "https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Layers: \n",
    "n_inputs = 28*28\n",
    "\n",
    "#conv layer 1/2:\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 5\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "#pooling layer 1:\n",
    "pool1_fmaps = conv1_fmaps\n",
    "pool1_ksize = 2\n",
    "pool1_stride = 2\n",
    "pool1_pad = \"SAME\"\n",
    "pool1_dropout_rate = 0.4\n",
    "\n",
    "#conv layer 3/4:\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "\n",
    "#pooling layer 2:\n",
    "pool2_fmaps = conv1_fmaps\n",
    "pool2_ksize = 2\n",
    "pool2_stride = 2\n",
    "pool2_pad = \"SAME\"\n",
    "pool2_dropout_rate = 0.4\n",
    "\n",
    "n_fc1 = 256\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make CNN Graph:\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "#output is 28x28*32\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "#output is 28x28*32\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "#output is 14x14*32\n",
    "with tf.name_scope(\"pool1\"):\n",
    "    pool1 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=pool1_pad, name=\"pool1\")\n",
    "    pool1_drop = tf.layers.dropout(pool1, pool1_dropout_rate, training=training)\n",
    "\n",
    "#output is 14x14*64\n",
    "conv3 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv3\")\n",
    "\n",
    "#output is 14x14*64\n",
    "conv4 = tf.layers.conv2d(conv3, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv4\")\n",
    "\n",
    "\n",
    "#output is 7*7*64 -> \n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, conv2_fmaps * 7 * 7])\n",
    "    pool2_flat_drop = tf.layers.dropout(pool2_flat, pool2_dropout_rate, training=training)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool2_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 64\n",
    "iteration = 0\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 50\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            iteration += 1\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss.eval(feed_dict={X: X_val, y: y_val})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(\"Epoch {}, last batch accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                  epoch, acc_batch * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "        \n",
    "        \n",
    "    #insert Test prediciton:    \n",
    "    acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "    print(\"Final accuracy on Validation set:\", acc_val)\n",
    "    notify(\"MNIST_Kaggle\", \"Completed Submission of CNN\")\n",
    "    save_path = saver.save(sess, \"./my_mnist_cnn2_model\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as tfs:\n",
    "    saver.restore(tfs, \"./my_mnist_cnn2_model\")\n",
    "    \n",
    "    pred = logits.eval(feed_dict={X: test})\n",
    "    prediction = np.argmax(pred, 1)\n",
    "    \n",
    "    create_submission(prediction, \"Submission_CNN2_\")\n",
    "    notify(\"MNIST_Kaggle\", \"Completed Submission of CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional Neural Network 3:\n",
    "based off:\n",
    "https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO CHANGE\n",
    "\n",
    "#CNN Layers: \n",
    "\n",
    "#inputs:\n",
    "n_inputs = 28*28\n",
    "\n",
    "#Group 1:\n",
    "#----------------------\n",
    "#conv layer 1/2:\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "#conv layer 3:\n",
    "conv3_fmaps = 32\n",
    "conv3_ksize = 5\n",
    "conv3_stride = 2\n",
    "conv3_pad = \"SAME\"\n",
    "\n",
    "#Dropout Layer:\n",
    "G1_dropout_rate = 0.4\n",
    "#----------------------\n",
    "\n",
    "\n",
    "#Group 2:\n",
    "#----------------------\n",
    "#conv layer 4/5:\n",
    "conv4_fmaps = 64\n",
    "conv4_ksize = 3\n",
    "conv4_stride = 1\n",
    "conv4_pad = \"SAME\"\n",
    "\n",
    "#conv layer 6:\n",
    "conv6_fmaps = 64\n",
    "conv6_ksize = 5\n",
    "conv6_stride = 2\n",
    "conv6_pad = \"SAME\"\n",
    "\n",
    "#Dropout Layer:\n",
    "G2_dropout_rate = 0.4\n",
    "#----------------------\n",
    "\n",
    "#Fully connected:\n",
    "n_fc1 = 128\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "#Output:\n",
    "n_outputs = 10\n",
    "\n",
    "#Saving location\n",
    "model_name = 'my_mnist_cnn3_model'\n",
    "save_path = os.path.join(MODEL_PATH, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make CNN Graph:\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"Group_1\"):\n",
    "    #output is 28x28*32\n",
    "    conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                             strides=conv1_stride, padding=conv1_pad,\n",
    "                             activation= tf.nn.relu, name=\"conv1\")\n",
    "    \n",
    "\n",
    "    #output is 28x28*32\n",
    "    conv2 = tf.layers.conv2d(conv1, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                             strides=conv1_stride, padding=conv1_pad,\n",
    "                             activation= tf.nn.relu, name=\"conv2\")  \n",
    "    \n",
    "    \n",
    "    #output is 14x14*32\n",
    "    conv3 = tf.layers.conv2d(conv2, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                             strides=conv3_stride, padding=conv3_pad,\n",
    "                             activation= tf.nn.relu, name=\"conv3\")  \n",
    "        \n",
    "  \n",
    "    c3_drop = tf.layers.dropout(conv3, G1_dropout_rate, training=training)\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"Group_2\"):\n",
    "    #output is 14x14*64\n",
    "    conv4 = tf.layers.conv2d(c3_drop, filters=conv4_fmaps, kernel_size=conv4_ksize,\n",
    "                             strides=conv4_stride, padding=conv4_pad,\n",
    "                             activation=tf.nn.relu, name=\"conv4\")\n",
    "    \n",
    "\n",
    "    #output is 14x14*64\n",
    "    conv5 = tf.layers.conv2d(conv4, filters=conv4_fmaps, kernel_size=conv4_ksize,\n",
    "                             strides=conv4_stride, padding=conv4_pad,\n",
    "                             activation=tf.nn.relu, name=\"conv5\") \n",
    "    \n",
    "    \n",
    "    #output is 7x7*64\n",
    "    conv6 = tf.layers.conv2d(conv5, filters=conv6_fmaps, kernel_size=conv6_ksize,\n",
    "                             strides=conv6_stride, padding=conv6_pad,\n",
    "                             activation=tf.nn.relu, name=\"conv6\")  \n",
    "        \n",
    "\n",
    "    c6_flat = tf.reshape(conv6, shape=[-1, conv6_fmaps * 7 * 7])\n",
    "    c6_drop = tf.layers.dropout(c6_flat, G2_dropout_rate, training=training)\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"Fully_connected\"):\n",
    "    fc1 = tf.layers.dense(c6_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 64 #change to 64 later\n",
    "iteration = 0\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 30\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            iteration += 1\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss.eval(feed_dict={X: X_val, y: y_val})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(\"Epoch: {}\\tBatch accuracy: {:.4f}%\\tValidation accuracy: {:.4f}%\\tBest Validation Loss: {:.6f}\".\n",
    "              format(epoch, acc_batch*100, acc_val*100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "        \n",
    "        \n",
    "    #insert Test prediciton:    \n",
    "    acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "    print(\"Final accuracy on Validation set:\", acc_val)\n",
    "    notify(\"MNIST_Kaggle\", \"Completed Submission of CNN\")\n",
    "    saved_path = saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as tfs:\n",
    "    saver.restore(tfs, save_path)\n",
    "    \n",
    "    pred = logits.eval(feed_dict={X: test})\n",
    "    prediction = np.argmax(pred, 1)\n",
    "    \n",
    "    create_submission(prediction, \"Submission_CNN3_\")\n",
    "    notify(\"MNIST_Kaggle\", \"Completed Submission of CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional Neural Network 4:\n",
    "## With Ensamble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Layers: \n",
    "n_inputs = 28*28\n",
    "\n",
    "#conv layer 1/2:\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 5\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "#pooling layer 1:\n",
    "pool1_fmaps = conv1_fmaps\n",
    "pool1_ksize = 2\n",
    "pool1_stride = 2\n",
    "pool1_pad = \"SAME\"\n",
    "pool1_dropout_rate = 0.4\n",
    "\n",
    "#conv layer 3/4:\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "\n",
    "#pooling layer 2:\n",
    "pool2_fmaps = conv2_fmaps\n",
    "pool2_ksize = 2\n",
    "pool2_stride = 2\n",
    "pool2_pad = \"SAME\"\n",
    "pool2_dropout_rate = 0.4\n",
    "\n",
    "n_fc1 = 256\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "n_outputs = 10\n",
    "\n",
    "#Saving location\n",
    "model_name = 'Ensamble/my_mnist_cnn_ensamble_'\n",
    "save_path = os.path.join(MODEL_PATH, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on: https://www.kaggle.com/elcaiseri/mnist-with-accuracy-0-999\n",
    "\n",
    "#Make CNN Graph:\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "#output is 28x28*32\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=64, kernel_size=3,\n",
    "                         strides=1, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "#output is 28x28*32\n",
    "conv2 = tf.layers.conv2d(conv1, filters=64, kernel_size=3,\n",
    "                         strides=1, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "#output is 14x14*32\n",
    "with tf.name_scope(\"pool1\"):\n",
    "    pool1 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=\"SAME\", name=\"pool1\")\n",
    "    pool1_drop = tf.layers.dropout(pool1, pool1_dropout_rate, training=training)\n",
    "    \n",
    "\n",
    "\n",
    "#output is 14x14*64\n",
    "conv3 = tf.layers.conv2d(pool1, filters=128, kernel_size=3,\n",
    "                         strides=1, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv3\")\n",
    "\n",
    "#output is 14x14*64\n",
    "conv4 = tf.layers.conv2d(conv3, filters=128, kernel_size=3,\n",
    "                         strides=1, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv4\")\n",
    "\n",
    "#output is 14x14*32\n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=\"SAME\", name=\"pool1\")\n",
    "    pool2_drop = tf.layers.dropout(pool2, pool1_dropout_rate, training=training)\n",
    "    \n",
    "    \n",
    "#output is 14x14*64\n",
    "conv5 = tf.layers.conv2d(pool2, filters=256, kernel_size=3,\n",
    "                         strides=1, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv5\")\n",
    "\n",
    "#output is 7*7*64 -> \n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv5, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, 256 * 3 * 3])\n",
    "    pool3_flat_drop = tf.layers.dropout(pool3_flat, pool2_dropout_rate, training=training)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make CNN Graph:\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "#output is 28x28*32\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "#output is 28x28*32\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "#output is 14x14*32\n",
    "with tf.name_scope(\"pool1\"):\n",
    "    pool1 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                           padding=pool1_pad, name=\"pool1\")\n",
    "    pool1_drop = tf.layers.dropout(pool1, pool1_dropout_rate, training=training)\n",
    "\n",
    "#output is 14x14*64\n",
    "conv3 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv3\")\n",
    "\n",
    "#output is 14x14*64\n",
    "conv4 = tf.layers.conv2d(conv3, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv4\")\n",
    "\n",
    "\n",
    "#output is 7*7*64 -> \n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, conv2_fmaps * 7 * 7])\n",
    "    pool2_flat_drop = tf.layers.dropout(pool2_flat, pool2_dropout_rate, training=training)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool2_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 64\n",
    "check_interval = 500\n",
    "max_checks_without_progress = 20\n",
    "ensable_num = 10\n",
    "\n",
    "for cnn_num in range(ensable_num):\n",
    "    iteration = 0\n",
    "    best_loss_val = np.infty\n",
    "    checks_since_last_progress = 0\n",
    "    best_model_params = None \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "                iteration += 1\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "                if iteration % check_interval == 0:\n",
    "                    loss_val = loss.eval(feed_dict={X: X_val, y: y_val})\n",
    "                    if loss_val < best_loss_val:\n",
    "                        best_loss_val = loss_val\n",
    "                        checks_since_last_progress = 0\n",
    "                        best_model_params = get_model_params()\n",
    "                    else:\n",
    "                        checks_since_last_progress += 1\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "            print(\"Epoch {}, last batch accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                      epoch, acc_batch * 100, acc_val * 100, best_loss_val))\n",
    "            if checks_since_last_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "        if best_model_params:\n",
    "            restore_model_params(best_model_params)\n",
    "        \n",
    "        print('Done with CNN_'+str(cnn_num))\n",
    "        \n",
    "        #insert Test prediciton:    \n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(\"Final accuracy on Validation set:\", acc_val)\n",
    "        msg = \"Completed training of CNN_4_\"+str(cnn_num)\n",
    "        notify(\"MNIST_Kaggle\", msg)\n",
    "        \n",
    "        en_name = model_name + str(cnn_num+10)\n",
    "        en_save = os.path.join(MODEL_PATH, en_name)\n",
    "        save_path = saver.save(sess, en_save)\n",
    "        \n",
    "notify(\"MNIST_Kaggle\", \"Completed Ensamble Training!!!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving location\n",
    "model_name = 'Ensamble/my_mnist_cnn_ensamble_'\n",
    "save_path = os.path.join(MODEL_PATH, model_name)\n",
    "\n",
    "#Ensamble Predictions:\n",
    "lables = []\n",
    "\n",
    "for cnn in range(ensable_num):\n",
    "     with tf.Session() as tfs:\n",
    "            en_name = model_name + str(cnn)\n",
    "            en_save = os.path.join(MODEL_PATH, en_name)        \n",
    "            saver.restore(tfs, en_save)\n",
    "            pred = logits.eval(feed_dict={X: test})\n",
    "            lables.append(pred)\n",
    "\n",
    "        \n",
    "ens_label = np.mean(lables, axis=0)\n",
    "prediction = np.argmax(ens_label, 1)\n",
    "create_submission(prediction, \"Submission_Ens_\")\n",
    "notify(\"MNIST_Kaggle\", \"Completed Submission of CNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
