{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "## Daniel Wilcox: 19147414\n",
    "\n",
    "This example problem can be found within chapter 7 of the \"Hands-on Machine Learning with Scikit-Learn and TensorFlow\" by Aurélien Géron. \n",
    "\n",
    "This project will be investigating the theory behind Dimensionality Reduction and how to implament them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports for operating system, unzip and URL's\n",
    "import os\n",
    "from six.moves import urllib\n",
    "from scipy.io import loadmat\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import time\n",
    "\n",
    "#Graphics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Array Manipulation\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#Shuffles data to test/train sets that represent the original data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "#Creating custom Transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import random\n",
    "\n",
    "#Model Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Image shifting\n",
    "from scipy.ndimage.interpolation import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Location to save the dataset\n",
    "MNIST_PATH = \"datasets/MNIST\"\n",
    "MNIST_URL = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "MNIST_MAT = \"/mnist-original.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST_data(mnist_path=MNIST_PATH, mnist_mat=MNIST_MAT):\n",
    "        mnist_raw = loadmat(mnist_path+mnist_mat)\n",
    "        mnist = {\"data\": mnist_raw[\"data\"].T,\n",
    "                 \"target\": mnist_raw[\"label\"][0],\n",
    "                 \"Col_names\": [\"target\", \"data\"],\n",
    "                 \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "                }\n",
    "        print(\"Data Successfully extracted from mnist.mat!\")\n",
    "        return mnist\n",
    "        \n",
    "    \n",
    "def get_MNIST_data(mnist_path=MNIST_PATH, mnist_url=MNIST_URL, mnist_mat=MNIST_MAT):\n",
    "    \n",
    "    print(\"Checking if directory exists...\")\n",
    "    if not os.path.isdir(mnist_path):\n",
    "        os.makedirs(mnist_path)\n",
    "        print(\"Creating directory\")\n",
    "    \n",
    "    else: \n",
    "        print(\"Directory exists\")\n",
    "        \n",
    "        #------------------------------------------------------------------\n",
    "        #uncomment if connected to internet\n",
    "        #try:\n",
    "            #print(\"\\nAttempting to get MNIST data from mldata.org ...\")\n",
    "            #mnist = fetch_mldata('MNIST original')\n",
    "            #print(\"\\nSuccess!\")\n",
    "            #return mnist\n",
    "    \n",
    "        #except urllib.error.HTTPError as ex:\n",
    "            #print(\"\\nCan't reach mldata.org, attempting alternative...\")\n",
    "            #print(\"Checking if mnist.mat file exists...\")  \n",
    "            \n",
    "        #------------------------------------------------------------------\n",
    "        #followig if, else should fall under 'except' \n",
    "            \n",
    "        if os.path.isfile(mnist_path+mnist_mat):\n",
    "            print(\"mnist.mat file does exists...\")\n",
    "            print(\"extracting data from mnist.mat...\")\n",
    "            \n",
    "            mnist = load_MNIST_data(mnist_path, mnist_mat)\n",
    "            print(\"\\nSuccess!\")\n",
    "            return mnist\n",
    "        \n",
    "        else:\n",
    "            print(\"mnist.mat file doesn't exists...\")\n",
    "            print(\"downloading mnist.mat file...\")\n",
    "            url_response = urllib.request.urlopen(mnist_url)\n",
    "            \n",
    "            print(\"\\nCreating .mat file\")\n",
    "            with open(mnist_path+mnist_mat, \"wb\") as f:\n",
    "                contents = url_response.read()\n",
    "                f.write(contents)\n",
    "            mnist = load_MNIST_data(mnist_path, mnist_mat)\n",
    "            print(\"\\nSuccess!\")\n",
    "            return mnist\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "## 8. \n",
    "Load the MNIST dataset (introduced in Chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing). Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set. Next, use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%. Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster? Next evaluate the classifier on the test set: how does it compare to the previous classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if directory exists...\n",
      "Directory exists\n",
      "mnist.mat file does exists...\n",
      "extracting data from mnist.mat...\n",
      "Data Successfully extracted from mnist.mat!\n",
      "\n",
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.]),\n",
       " 'Col_names': ['target', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = get_MNIST_data(MNIST_PATH, MNIST_URL, MNIST_MAT)\n",
    "mnist            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of \"Data\": (70000, 784)\n",
      "Shape of \"target\": (70000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(\"Shape of \\\"Data\\\": {}\\nShape of \\\"target\\\": {}\\n\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST is already split into train and test\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle training set to guarentee cross-validation folds are similar.\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest took 5.29s to fit the data\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10,)\n",
    "\n",
    "#Time Training\n",
    "t_start = time.time()\n",
    "forest.fit(X_train, y_train)\n",
    "t_end = time.time()\n",
    "\n",
    "t = t_end - t_start\n",
    "\n",
    "print(\"Random forest took {:.2f}s to fit the data\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy score: 94.90%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Results:\n",
    "y_pred = forest.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random forest accuracy score: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pca = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "#PCA with 95%:\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced_tr = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest took 9.37s to fit the data\n"
     ]
    }
   ],
   "source": [
    "#Time Training with PCA\n",
    "t_start = time.time()\n",
    "forest_pca.fit(X_reduced_tr, y_train)\n",
    "t_end = time.time()\n",
    "\n",
    "t = t_end - t_start\n",
    "\n",
    "print(\"Random forest took {:.2f}s to fit the data\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest with PCA's accuracy score: 89.64%\n"
     ]
    }
   ],
   "source": [
    "#PCA took longer? \n",
    "#Evaluation:\n",
    "X_reduced_test = pca.transform(X_test)\n",
    "\n",
    "y_pred_pca = forest_pca.predict(X_reduced_test)\n",
    "acc_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "print(\"Random forest with PCA's accuracy score: {:.2f}%\".format(acc_pca*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\n",
    "Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using\n",
    "Matplotlib. You can use a scatterplot using 10 different colors to represent each image’s target\n",
    "class. Alternatively, you can write colored digits at the location of each instance, or even plot\n",
    "scaled-down versions of the digit images themselves (if you plot all digits, the visualization will\n",
    "be too cluttered, so you should either draw a random sample or plot an instance only if no other\n",
    "instance has already been plotted at a close distance). You should get a nice visualization with\n",
    "well-separated clusters of digits. Try using other dimensionality reduction algorithms such as\n",
    "PCA, LLE, or MDS and compare the resulting visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 10% of data\n",
    "frac_per = 0.10\n",
    "frac = round(frac_per*60000)\n",
    "frac_idx = np.random.permutation(60000)[:frac]\n",
    "\n",
    "X_less = X_train[frac_idx]\n",
    "y_less = y_train[frac_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-760922635322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#t-SNE reduction to 2-D:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_2D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_less\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \"\"\"\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    804\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter_without_progress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[0;32m--> 863\u001b[0;31m                                                           **opt_args)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compute_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error)\u001b[0m\n\u001b[1;32m    259\u001b[0m                                       \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                                       \u001b[0mdof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                                       compute_error=compute_error)\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#t-SNE reduction to 2-D:\n",
    "tsne = TSNE(n_components=2)\n",
    "X_2D = tsne.fit_transform(X_less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.scatter(X_2D[:, 0], X_2D[:, 1], c=y_less, cmap=\"jet\")\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previously seen that 3's and 5's got confused, comparing these two digits:\n",
    "idx_3_5 = (y == 3) | (y == 5) \n",
    "X_3_5 = X[idx_3_5]\n",
    "y_3_5 = y[idx_3_5]\n",
    "\n",
    "tsne_3_5 = TSNE(n_components=2)\n",
    "X_2D_3_5 = tsne_3_5.fit_transform(X_3_5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,10))\n",
    "for val in (3, 5):\n",
    "    plt.scatter(X_2D_3_5[y_3_5 == val, 0], X_2D_3_5[y_3_5 == val, 1], c=[cmap(val/9)])\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
