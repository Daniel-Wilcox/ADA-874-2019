{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: Titanic Challenge\n",
    "## Coded by Daniel Wilcox\n",
    "\n",
    "This is a notebook showing the process in predicting the survivors of the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.base import clone\n",
    "\n",
    "#Fills in values to empty data locations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Creating custom Transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Location to save the dataset\n",
    "TITANIC_PATH = \"datasets/titanic\"\n",
    "TITANIC_URL = \"https://github.com/Daniel-Wilcox/ADA-874-2019/blob/master/datasets/titanic/\"\n",
    "train_name = \"train.csv\" \n",
    "test_name = \"test.csv\" \n",
    "\n",
    "\n",
    "#The Location to save the models\n",
    "PICKLE_PATH = \"PickleModels/Titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle functions\n",
    "\n",
    "#Saving and storing the model\n",
    "def save_pickle(model_name, model, pic_path=PICKLE_PATH):\n",
    "    print(\"Saving model...\")\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(cwd+\"/\"+pic_path)\n",
    "        \n",
    "    f = open(model_name, \"wb\")\n",
    "    pickle.dump(model, f)\n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(cwd)\n",
    "    print(\"Saved \"+model_name+\" successfully!\\n\")\n",
    "    return None\n",
    "    \n",
    "    \n",
    "#Retrieving and loading the model\n",
    "def load_pickle(model_name, pic_path=PICKLE_PATH):\n",
    "    print(\"Loading \"+model_name+\" from Pickle file...\")\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(cwd+\"/\"+pic_path)\n",
    "    \n",
    "    f = open(model_name, \"rb\")\n",
    "    p = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(cwd)\n",
    "    print(model_name+\" successfully loaded!\\n\")\n",
    "    return p\n",
    "\n",
    "#Check whether the pickel exists\n",
    "def pickle_exist(model_name, pic_path=PICKLE_PATH):\n",
    "    #check if pickle file exists\n",
    "    print(\"Checking if pickle directory exists...\")\n",
    "    if not os.path.isdir(pic_path):\n",
    "        os.makedirs(pic_path)\n",
    "        print(\"Directory does NOT exists\")\n",
    "        print(\"Creating directory\")\n",
    "    \n",
    "    else: \n",
    "        print(\"Directory exists\")\n",
    "        \n",
    "    if os.path.isfile(pic_path+\"/\"+model_name):\n",
    "        print(\"Pickle file does exists...\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Pickle file does NOT exists...\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Titanic_data(file_name, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, file_name)\n",
    "    return pd.read_csv(csv_path)\n",
    "        \n",
    "    \n",
    "def get_Titanic_data(file_name, titanic_url=TITANIC_URL, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, file_name)\n",
    "    \n",
    "    print(\"Checking if directory exists...\")\n",
    "    if not os.path.isdir(titanic_path):\n",
    "        os.makedirs(titanic_path)\n",
    "        print(\"Creating directory\")\n",
    "    \n",
    "    else: \n",
    "        print(\"Directory exists\") \n",
    "            \n",
    "        if os.path.isfile(csv_path):\n",
    "            print(file_name + \" file does exists...\")\n",
    "            print(\"extracting \" + file_name)\n",
    "            \n",
    "            titanic = load_Titanic_data(file_name)\n",
    "            print(\"\\nSuccess!\")\n",
    "            return titanic\n",
    "        \n",
    "        else:\n",
    "            print(file_name + \" file doesn't exists...\")\n",
    "            print(\"Download .csv from Kaggle!\")\n",
    "\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if directory exists...\n",
      "Directory exists\n",
      "train.csv file does exists...\n",
      "extracting train.csv\n",
      "\n",
      "Success!\n",
      "Checking if directory exists...\n",
      "Directory exists\n",
      "test.csv file does exists...\n",
      "extracting test.csv\n",
      "\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "Train = get_Titanic_data(train_name)\n",
    "Test = get_Titanic_data(test_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variable - Definition                              - Key\n",
    "1. survival - Survival                                - 0/1 = No/Yes\n",
    "2. pclass   - Ticket class                            - 1,2,3 = 1st, 2nd, 3rd class\n",
    "3. sex      - Sex                                     - male, female\n",
    "4. Age      - Age in years                            - ...\n",
    "5. sibsp    - # of siblings/spouses on the Titanic    - ...\n",
    "6. parch    - # of parents/children on the Titanic    - ...\n",
    "7. ticket   - Ticket number                           - ...\n",
    "8. fare     - Passenger fare                          - ...\n",
    "9. cabin    - Cabin number                            - ...\n",
    "10. embarked - Port of Embarkation                     - C = Cherbourg, Q = Queenstown, S = Southampton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.38% Survived\n",
      "61.62% Died\n"
     ]
    }
   ],
   "source": [
    "sur = Train[\"Survived\"].value_counts() / len(Train)\n",
    "print(\"{:.2f}% Survived\\n{:.2f}% Died\".format(100*sur[1],100*sur[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       1.000000\n",
       "Fare           0.257307\n",
       "Parch          0.081629\n",
       "PassengerId   -0.005007\n",
       "SibSp         -0.035322\n",
       "Age           -0.077221\n",
       "Pclass        -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation matrix\n",
    "corr_matrix = Train.corr()\n",
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separtate labels from features\n",
    "y_train = Train[\"Survived\"].copy()\n",
    "X_tr = Train.drop(\"Survived\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Features (survived is already removed)\n",
    "list_drop = ['Name', 'Ticket', 'Cabin']\n",
    "\n",
    "Dropped = X_tr[list(set(X_tr.columns) - set(list_drop))]\n",
    "\n",
    "#Numeric Features\n",
    "list_num = Dropped.select_dtypes(include = [\"number\"]).columns\n",
    "\n",
    "#Catagorical Features (to be transformed into OHE)\n",
    "list_cat = Dropped.select_dtypes(include = [\"object\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return(self)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.feature_names].values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numeric Transformations\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', Selector(list_num)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "#Catagorical Transformations\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', Selector(list_cat)),\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perpare_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "X_train = perpare_pipeline.fit_transform(X_tr)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaled Test Set for predictions:\n",
    "X_test = perpare_pipeline.fit_transform(Test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading lin_clf from Pickle file...\n",
      "lin_clf successfully loaded!\n",
      "\n",
      "lin_clf 1: 80.13%\n",
      "lin_clf 2: 79.80%\n",
      "lin_clf 3: 78.11%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#To create new model if pickle already even if pickle exists; load_pkl = False\n",
    "load_pkl = True\n",
    "\n",
    "    \n",
    "#Linear Support Vector Classifier\n",
    "if pickle_exist(\"lin_clf\") and load_pkl:\n",
    "    lin_clf = load_pickle(\"lin_clf\")\n",
    "else:\n",
    "    lin_clf = LinearSVC()\n",
    "    lin_clf.fit(X_train, y_train)\n",
    "    save_pickle(\"lin_clf\", lin_clf)\n",
    "    \n",
    "    \n",
    "cvs = cross_val_score(lin_clf, X_train, y_train, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "print(\"lin_clf 1: {:.2f}%\\nlin_clf 2: {:.2f}%\\nlin_clf 3: {:.2f}%\\n\"\n",
    "      .format(cvs[0]*100, cvs[1]*100, cvs[2]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading svc_clf from Pickle file...\n",
      "svc_clf successfully loaded!\n",
      "\n",
      "svc_clf 1: 81.48%\n",
      "svc_clf 2: 82.83%\n",
      "svc_clf 3: 83.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine Classifier    \n",
    "if pickle_exist(\"svc_clf\") and load_pickle:\n",
    "    svc_clf = load_pickle(\"svc_clf\")\n",
    "else:\n",
    "    svc_clf = SVC()\n",
    "    svc_clf.fit(X_train, y_train)\n",
    "    save_pickle(\"svc_clf\", svc_clf)\n",
    "    \n",
    "    \n",
    "cvs = cross_val_score(svc_clf, X_train, y_train, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "print(\"svc_clf 1: {:.2f}%\\nsvc_clf 2: {:.2f}%\\nsvc_clf 3: {:.2f}%\\n\"\n",
    "      .format(cvs[0]*100, cvs[1]*100, cvs[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved log_reg_clf successfully!\n",
      "\n",
      "log_reg_clf 1: 78.79%\n",
      "log_reg_clf 2: 77.78%\n",
      "log_reg_clf 3: 79.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "if pickle_exist(\"log_reg_clf\") and load_pickle:\n",
    "    log_reg_clf = load_pickle(\"log_reg_clf\")\n",
    "else:\n",
    "    log_reg_clf = LogisticRegression()\n",
    "    log_reg_clf.fit(X_train, y_train)\n",
    "    save_pickle(\"log_reg_clf\", log_reg_clf)\n",
    "    \n",
    "    \n",
    "cvs = cross_val_score(log_reg_clf, X_train, y_train, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "print(\"log_reg_clf 1: {:.2f}%\\nlog_reg_clf 2: {:.2f}%\\nlog_reg_clf 3: {:.2f}%\\n\"\n",
    "      .format(cvs[0]*100, cvs[1]*100, cvs[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved tree_clf successfully!\n",
      "\n",
      "tree_clf 1: 59.60%\n",
      "tree_clf 2: 61.62%\n",
      "tree_clf 3: 71.72%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "if pickle_exist(\"tree_clf\") and load_pickle:\n",
    "    tree_clf = load_pickle(\"tree_clf\")\n",
    "else:\n",
    "    tree_clf = DecisionTreeClassifier()\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    save_pickle(\"tree_clf\", tree_clf)\n",
    "    \n",
    "    \n",
    "cvs = cross_val_score(tree_clf, X_train, y_train, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "print(\"tree_clf 1: {:.2f}%\\ntree_clf 2: {:.2f}%\\ntree_clf 3: {:.2f}%\\n\"\n",
    "      .format(cvs[0]*100, cvs[1]*100, cvs[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved randf_clf successfully!\n",
      "\n",
      "randf_clf 1: 81.14%\n",
      "randf_clf 2: 80.81%\n",
      "randf_clf 3: 83.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "if pickle_exist(\"randf_clf\") and load_pickle:\n",
    "    randf_clf = load_pickle(\"randf_clf\")\n",
    "else:\n",
    "    randf_clf = RandomForestClassifier()\n",
    "    randf_clf.fit(X_train, y_train)\n",
    "    save_pickle(\"randf_clf\", randf_clf)\n",
    "    \n",
    "    \n",
    "cvs = cross_val_score(randf_clf, X_train, y_train, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "print(\"randf_clf 1: {:.2f}%\\nrandf_clf 2: {:.2f}%\\nrandf_clf 3: {:.2f}%\\n\"\n",
    "      .format(cvs[0]*100, cvs[1]*100, cvs[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved sgd_clf successfully!\n",
      "\n",
      "sgd_clf 1: 72.39%\n",
      "sgd_clf 2: 76.43%\n",
      "sgd_clf 3: 79.46%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent Classifier  \n",
    "if pickle_exist(\"sgd_clf\") and load_pickle:\n",
    "    sgd_clf = load_pickle(\"sgd_clf\")\n",
    "else:\n",
    "    sgd_clf = SGDClassifier()\n",
    "    sgd_clf.fit(X_train, y_train)\n",
    "    save_pickle(\"sgd_clf\", sgd_clf)\n",
    "    \n",
    "    \n",
    "cvs = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "print(\"sgd_clf 1: {:.2f}%\\nsgd_clf 2: {:.2f}%\\nsgd_clf 3: {:.2f}%\\n\"\n",
    "      .format(cvs[0]*100, cvs[1]*100, cvs[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved knn_clf successfully!\n",
      "\n",
      "knn_clf 1: 77.44%\n",
      "knn_clf 2: 81.14%\n",
      "knn_clf 3: 80.47%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#K-nearest neighbors Classifier\n",
    "if pickle_exist(\"knn_clf\") and load_pickle:\n",
    "    knn_clf = load_pickle(\"knn_clf\")\n",
    "else:\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    save_pickle(\"knn_clf\", knn_clf)\n",
    "    \n",
    "    \n",
    "cvs = cross_val_score(knn_clf, X_train, y_train, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "print(\"knn_clf 1: {:.2f}%\\nknn_clf 2: {:.2f}%\\nknn_clf 3: {:.2f}%\\n\"\n",
    "      .format(cvs[0]*100, cvs[1]*100, cvs[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cross_val(clf, name_clf, lp=load_pickle, cv=cv_split):\n",
    "    if pickle_exist(str(name_clf)) and lp:\n",
    "        ml_clf = load_pickle(str(name_clf))\n",
    "    else:\n",
    "        ml_clf = clf\n",
    "        ml_clf.fit(X_train, y_train)\n",
    "        save_pickle(str(name_clf), ml_clf)\n",
    "    cvs =  cross_val_score(ml_clf, X_train, y_train, cv=3, scoring=\"accuracy\") \n",
    "    return  np.mean(cvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading LinearSVC from Pickle file...\n",
      "LinearSVC successfully loaded!\n",
      "\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading SVC from Pickle file...\n",
      "SVC successfully loaded!\n",
      "\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading LogisticRegression from Pickle file...\n",
      "LogisticRegression successfully loaded!\n",
      "\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading DecisionTreeClassifier from Pickle file...\n",
      "DecisionTreeClassifier successfully loaded!\n",
      "\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading RandomForestClassifier from Pickle file...\n",
      "RandomForestClassifier successfully loaded!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading SGDClassifier from Pickle file...\n",
      "SGDClassifier successfully loaded!\n",
      "\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading KNeighborsClassifier from Pickle file...\n",
      "KNeighborsClassifier successfully loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_options = [          \n",
    "    LinearSVC(),\n",
    "    SVC(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SGDClassifier(),\n",
    "    KNeighborsClassifier()\n",
    "    ]          \n",
    " \n",
    "compare_col = ['Clf Name', 'Clf Parameters', 'Clf Mean Accuracy'] \n",
    "clf_compare = pd.DataFrame(columns = compare_col)\n",
    "          \n",
    "          \n",
    "row=0\n",
    "          \n",
    "for clf in clf_options: \n",
    "    clf_name = clf.__class__.__name__\n",
    "                    \n",
    "    clf_compare.loc[row, 'Clf Name'] = clf_name\n",
    "    clf_compare.loc[row, 'Clf Parameters'] = str(clf.get_params()) \n",
    "    cvs = model_cross_val(clf, clf_name)\n",
    "    \n",
    "    clf_compare.loc[row, 'Clf Mean Accuracy'] = cvs\n",
    "    \n",
    "    row +=1\n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clf Name</th>\n",
       "      <th>Clf Parameters</th>\n",
       "      <th>Clf Mean Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'class_weight': ...</td>\n",
       "      <td>0.824916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.796857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.79349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.792368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.65881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.643098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Clf Name                                     Clf Parameters  \\\n",
       "1                     SVC  {'C': 1.0, 'cache_size': 200, 'class_weight': ...   \n",
       "6    KNeighborsClassifier  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "0               LinearSVC  {'C': 1.0, 'class_weight': None, 'dual': True,...   \n",
       "4  RandomForestClassifier  {'bootstrap': True, 'class_weight': None, 'cri...   \n",
       "2      LogisticRegression  {'C': 1.0, 'class_weight': None, 'dual': False...   \n",
       "3  DecisionTreeClassifier  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "5           SGDClassifier  {'alpha': 0.0001, 'average': False, 'class_wei...   \n",
       "\n",
       "  Clf Mean Accuracy  \n",
       "1          0.824916  \n",
       "6          0.796857  \n",
       "0           0.79349  \n",
       "4          0.792368  \n",
       "2          0.787879  \n",
       "3           0.65881  \n",
       "5          0.643098  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_compare.sort_values(by = 'Clf Mean Accuracy', ascending = False, inplace = True)\n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters of classifiers:\n",
    "\n",
    "#Linear SVC\n",
    "lin_svc_param = {\n",
    "    'loss':('hinge','squared_hinge'),\n",
    "    'C':[1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "#SVC\n",
    "svc_param = {\n",
    "    'C' : [1, 2, 5, 10],\n",
    "    'kernel' : ['linear', 'rbf'],\n",
    "    'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "#Logistic Regression\n",
    "log_reg_param = {\n",
    "    'C': [1, 2, 5, 10],\n",
    "    'penalty' : ['l1', 'l2']\n",
    "}\n",
    "\n",
    "#Decision Tree Classifier\n",
    "tree_param = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'max_depth' : [1, 2, 3, 5]\n",
    "}\n",
    "\n",
    "#Random Forest Classifier\n",
    "forest_param = {\n",
    "    'n_estimators' : [100, 200, 500],\n",
    "    'criterion' : ['gini'],\n",
    "    'max_features' : [1, 3, 5, 10],\n",
    "    'min_samples_split' : [2, 3, 5, 10],\n",
    "    'min_samples_leaf' : [1, 2, 3, 10]\n",
    "}\n",
    "\n",
    "#SGDClassifier\n",
    "SGDC_param = {\n",
    "    'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "#K-Neighbors Classifier\n",
    "k_neigh_param = {\n",
    "    'n_neighbors': [3, 4, 5],\n",
    "    'weights': ['uniform','distance']\n",
    "}\n",
    "\n",
    "param_option = [\n",
    "    lin_svc_param,\n",
    "    svc_param,\n",
    "    log_reg_param,\n",
    "    tree_param,\n",
    "    forest_param,\n",
    "    SGDC_param,\n",
    "    k_neigh_param \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_grid(clf, name_clf, clf_param, lp=load_pickle, cv=cv_split): \n",
    "\n",
    "    gs_clf = GridSearchCV(clf, param_grid=clf_param, cv=cv_split, \n",
    "                          verbose=2, n_jobs=-1, scoring='accuracy')\n",
    "    \n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_est = gs_clf.best_estimator_\n",
    "    best_sco = gs_clf.best_score_ \n",
    "    \n",
    "    text_check = os.path.isfile(PICKLE_PATH+\"/best_score_\"+str(name_clf)+\".txt\")\n",
    "    \n",
    "    if pickle_exist(\"best_\"+str(name_clf)) and text_check and lp:\n",
    "        #load current best score\n",
    "        prev_best_score = max(np.loadtxt((PICKLE_PATH+\"/best_score_\"+str(name_clf)+\".txt\"), dtype=float))\n",
    "\n",
    "        if best_sco > prev_best_score:\n",
    "            temp = [best_sco, best_sco]\n",
    "            np.savetxt(PICKLE_PATH+\"/best_score_\"+str(name_clf)+\".txt\", temp, fmt='%f')\n",
    "            save_pickle(\"best_\"+str(name_clf), best_est)\n",
    "        else:\n",
    "            #load in better parameters\n",
    "            best_sco = max(np.loadtxt(PICKLE_PATH+\"/best_score_\"+str(name_clf)+\".txt\", dtype=float))\n",
    "            best_est = load_pickle(\"best_\"+str(name_clf))\n",
    "    else:\n",
    "        #make pickles if dont exist\n",
    "        temp = [best_sco, best_sco]\n",
    "        np.savetxt(PICKLE_PATH+\"/best_score_\"+str(name_clf)+\".txt\", temp, fmt='%f')\n",
    "        save_pickle(\"best_\"+str(name_clf), best_est)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: LinearSVC - {'loss': ('hinge', 'squared_hinge'), 'C': [1, 2, 5, 10]}\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:    2.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    2.4s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading best_LinearSVC from Pickle file...\n",
      "best_LinearSVC successfully loaded!\n",
      "\n",
      "Loading best_LinearSVC from Pickle file...\n",
      "best_LinearSVC successfully loaded!\n",
      "\n",
      "1: SVC - {'C': [1, 2, 5, 10], 'kernel': ['linear', 'rbf'], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  32 out of  96 | elapsed:    0.5s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  24 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.1s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading best_SVC from Pickle file...\n",
      "best_SVC successfully loaded!\n",
      "\n",
      "Loading best_SVC from Pickle file...\n",
      "best_SVC successfully loaded!\n",
      "\n",
      "2: LogisticRegression - {'C': [1, 2, 5, 10], 'penalty': ['l1', 'l2']}\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Saving model...\n",
      "Saved best_LogisticRegression successfully!\n",
      "\n",
      "Loading best_LogisticRegression from Pickle file...\n",
      "best_LogisticRegression successfully loaded!\n",
      "\n",
      "3: DecisionTreeClassifier - {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_depth': [1, 2, 3, 5]}\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  48 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does exists...\n",
      "Loading best_DecisionTreeClassifier from Pickle file...\n",
      "best_DecisionTreeClassifier successfully loaded!\n",
      "\n",
      "Loading best_DecisionTreeClassifier from Pickle file...\n",
      "best_DecisionTreeClassifier successfully loaded!\n",
      "\n",
      "4: RandomForestClassifier - {'n_estimators': [100, 200, 500], 'criterion': ['gini'], 'max_features': [1, 3, 5, 10], 'min_samples_split': [2, 3, 5, 10], 'min_samples_leaf': [1, 2, 3, 10]}\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed:   50.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved best_RandomForestClassifier successfully!\n",
      "\n",
      "Loading best_RandomForestClassifier from Pickle file...\n",
      "best_RandomForestClassifier successfully loaded!\n",
      "\n",
      "5: SGDClassifier - {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved best_SGDClassifier successfully!\n",
      "\n",
      "Loading best_SGDClassifier from Pickle file...\n",
      "best_SGDClassifier successfully loaded!\n",
      "\n",
      "6: KNeighborsClassifier - {'n_neighbors': [3, 4, 5], 'weights': ['uniform', 'distance']}\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Checking if pickle directory exists...\n",
      "Directory exists\n",
      "Pickle file does NOT exists...\n",
      "Saving model...\n",
      "Saved best_KNeighborsClassifier successfully!\n",
      "\n",
      "Loading best_KNeighborsClassifier from Pickle file...\n",
      "best_KNeighborsClassifier successfully loaded!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  18 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  18 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "best_col = ['Clf Name', 'Best Clf Parameters', 'Best Clf Accuracy Score'] \n",
    "best_compare = pd.DataFrame(columns = best_col)\n",
    "          \n",
    "          \n",
    "row=0\n",
    "\n",
    "for clf, param in zip(clf_options, param_option): \n",
    "    \n",
    "    clf_name = clf.__class__.__name__\n",
    "    best_compare.loc[row, 'Clf Name'] = clf_name\n",
    "    \n",
    "    print(\"{}: {} - {}\".format(row, clf_name, param))\n",
    "    \n",
    "    model_grid(clf, clf_name, param)\n",
    "    \n",
    "    best_score = max(np.loadtxt((PICKLE_PATH+\"/best_score_\"+str(clf_name)+\".txt\"), dtype=float))\n",
    "    best_clf = load_pickle(\"best_\"+str(clf_name))\n",
    "    \n",
    "    best_compare.loc[row, 'Best Clf Parameters'] = str(best_clf.get_params())\n",
    "    best_compare.loc[row, 'Best Clf Accuracy Score'] = str(best_score)\n",
    "    \n",
    "    row +=1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clf Name</th>\n",
       "      <th>Best Clf Parameters</th>\n",
       "      <th>Best Clf Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.806331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1, 'cache_size': 200, 'class_weight': No...</td>\n",
       "      <td>0.798883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.793296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'dual': True, ...</td>\n",
       "      <td>0.787709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 2, 'class_weight': None, 'dual': False, ...</td>\n",
       "      <td>0.785847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.01, 'average': False, 'class_weigh...</td>\n",
       "      <td>0.780261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.769088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Clf Name                                Best Clf Parameters  \\\n",
       "4  RandomForestClassifier  {'bootstrap': True, 'class_weight': None, 'cri...   \n",
       "1                     SVC  {'C': 1, 'cache_size': 200, 'class_weight': No...   \n",
       "3  DecisionTreeClassifier  {'class_weight': None, 'criterion': 'entropy',...   \n",
       "0               LinearSVC  {'C': 10, 'class_weight': None, 'dual': True, ...   \n",
       "2      LogisticRegression  {'C': 2, 'class_weight': None, 'dual': False, ...   \n",
       "5           SGDClassifier  {'alpha': 0.01, 'average': False, 'class_weigh...   \n",
       "6    KNeighborsClassifier  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "\n",
       "  Best Clf Accuracy Score  \n",
       "4                0.806331  \n",
       "1                0.798883  \n",
       "3                0.793296  \n",
       "0                0.787709  \n",
       "2                0.785847  \n",
       "5                0.780261  \n",
       "6                0.769088  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_compare.sort_values(by = 'Best Clf Accuracy Score', ascending = False, inplace = True)\n",
    "best_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best(clf):\n",
    "    clf_name = clf.__class__.__name__\n",
    "    return load_pickle(\"best_\"+str(clf_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 712 entries, Verificaiton set: 179 entries\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, ver_index in split.split(Train, Train[\"Survived\"]):\n",
    "    Train_strat = Train.loc[train_index]\n",
    "    Ver_strat = Train.loc[ver_index]\n",
    "\n",
    "print(\"Training set: {} entries, Verificaiton set: {} entries\".format(len(Train_strat),len(Ver_strat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training = Train_strat[\"Survived\"].copy()\n",
    "X_tr = Train_strat.drop(\"Survived\", axis=1)\n",
    "X_training = perpare_pipeline.fit_transform(X_tr)\n",
    "\n",
    "y_verification = Ver_strat[\"Survived\"].copy()\n",
    "X_ver = Ver_strat.drop(\"Survived\", axis=1)\n",
    "X_verification = perpare_pipeline.fit_transform(X_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best_LinearSVC from Pickle file...\n",
      "best_LinearSVC successfully loaded!\n",
      "\n",
      "Loading best_SVC from Pickle file...\n",
      "best_SVC successfully loaded!\n",
      "\n",
      "Loading best_LogisticRegression from Pickle file...\n",
      "best_LogisticRegression successfully loaded!\n",
      "\n",
      "Loading best_DecisionTreeClassifier from Pickle file...\n",
      "best_DecisionTreeClassifier successfully loaded!\n",
      "\n",
      "Loading best_RandomForestClassifier from Pickle file...\n",
      "best_RandomForestClassifier successfully loaded!\n",
      "\n",
      "Loading best_SGDClassifier from Pickle file...\n",
      "best_SGDClassifier successfully loaded!\n",
      "\n",
      "Loading best_KNeighborsClassifier from Pickle file...\n",
      "best_KNeighborsClassifier successfully loaded!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lin_svc', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)), ('svc', SVC(C=1, cache_size=200, class_weight=None, coef0=0....ki',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svc = load_best(clf_options[0])\n",
    "svc = load_best(clf_options[1])\n",
    "log_reg = load_best(clf_options[2])\n",
    "tree = load_best(clf_options[3])\n",
    "forest = load_best(clf_options[4])\n",
    "SGDC = load_best(clf_options[5])\n",
    "knn = load_best(clf_options[6])\n",
    "\n",
    "\n",
    "est = [('lin_svc', lin_svc), ('svc', svc), ('log_reg', log_reg),\n",
    "       ('tree', tree), ('forest', forest), ('SGDC', SGDC),\n",
    "       ('knn', knn)]\n",
    "\n",
    "vote_clf = VotingClassifier(estimators=est, voting='hard')\n",
    "\n",
    "vote_clf.fit(X_training, y_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC: 79.33%\n",
      "SVC: 81.56%\n",
      "LogisticRegression: 79.33%\n",
      "DecisionTreeClassifier: 79.89%\n",
      "RandomForestClassifier: 79.89%\n",
      "SGDClassifier: 79.33%\n",
      "KNeighborsClassifier: 77.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier: 81.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for clf in (lin_svc, svc, log_reg, tree, \n",
    "            forest, SGDC, knn, vote_clf):\n",
    "    \n",
    "    clf.fit(X_training, y_training)\n",
    "    y_pred = clf.predict(X_verification)\n",
    "    \n",
    "    name = clf.__class__.__name__\n",
    "    score = accuracy_score(y_verification, y_pred)\n",
    "    \n",
    "    print(\"{}: {:.2f}%\".format(name, 100*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lin_svc', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)), ('svc', SVC(C=1, cache_size=200, class_weight=None, coef0=0....ki',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit to whole dataset\n",
    "vote_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIX THIS PROPER\n",
    "\n",
    "def make_csv(csv_name, save_loc=TITANIC_PATH):\n",
    "    curr_path = os.getcwd()\n",
    "    save_path = os.path.join(curr_path, save_loc)\n",
    "    os.chdir(save_path)\n",
    "    \n",
    "    max_i = 0\n",
    "    \n",
    "    len_name = len(csv_name)\n",
    "           \n",
    "    for file in glob.glob(csv_name+'*.csv'):\n",
    "        \n",
    "        file_name = file[:len(file)-4]\n",
    "        file_ver = file_name[len_name:]\n",
    "        \n",
    "        if int(file_ver) > max_i:\n",
    "            max_i = int(file_ver)\n",
    "        \n",
    "    new_ver = csv_name+str(max_i+1)+'.csv'\n",
    "        \n",
    "        \n",
    "        \n",
    "    os.chdir(curr_path)\n",
    "    \n",
    "    return os.path.join(save_path, new_ver)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerId = Test['PassengerId']\n",
    "\n",
    "Survived_pred = vote_clf.predict(X_test) \n",
    "\n",
    "\n",
    "Submission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
    "                            'Survived': Survived_pred })\n",
    "\n",
    "name = \"Submission\"\n",
    "file_name = make_csv(name)\n",
    "\n",
    "Submission.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/Daniel/Desktop/ADA/WeekExercises/GitHubSaves/ADA-874-2019') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
