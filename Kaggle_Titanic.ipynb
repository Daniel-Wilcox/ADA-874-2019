{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: Titanic Challenge\n",
    "## Coded by Daniel Wilcox\n",
    "\n",
    "This is a notebook showing the process in predicting the survivors of the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "#Fills in values to empty data locations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Creating custom Transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Location to save the dataset\n",
    "TITANIC_PATH = \"datasets/titanic\"\n",
    "TITANIC_URL = \"https://github.com/Daniel-Wilcox/ADA-874-2019/blob/master/datasets/titanic/\"\n",
    "train_name = \"train.csv\" \n",
    "test_name = \"test.csv\" \n",
    "\n",
    "\n",
    "#The Location to save the models\n",
    "PICKLE_PATH = \"PickleModels/Titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle functions\n",
    "\n",
    "#Saving and storing the model\n",
    "def save_pickle(model_name, model, pic_path=PICKLE_PATH):\n",
    "    print(\"Saving model...\")\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(cwd+\"/\"+pic_path)\n",
    "        \n",
    "    f = open(model_name, \"wb\")\n",
    "    pickle.dump(model, f)\n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(cwd)\n",
    "    print(\"Saved \"+model_name+\" successfully!\\n\")\n",
    "    return None\n",
    "    \n",
    "    \n",
    "#Retrieving and loading the model\n",
    "def load_pickle(model_name, pic_path=PICKLE_PATH):\n",
    "    print(\"Loading \"+model_name+\" from Pickle file...\")\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(cwd+\"/\"+pic_path)\n",
    "    \n",
    "    f = open(model_name, \"rb\")\n",
    "    p = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(cwd)\n",
    "    print(model_name+\" successfully loaded!\\n\")\n",
    "    return p\n",
    "\n",
    "#Check whether the pickel exists\n",
    "def pickle_exist(model_name, pic_path=PICKLE_PATH):\n",
    "    #check if pickle file exists\n",
    "    print(\"Checking if pickle directory exists...\")\n",
    "    if not os.path.isdir(pic_path):\n",
    "        os.makedirs(pic_path)\n",
    "        print(\"Directory does NOT exists\")\n",
    "        print(\"Creating directory\")\n",
    "    \n",
    "    else: \n",
    "        print(\"Directory exists\")\n",
    "        \n",
    "    if os.path.isfile(pic_path+\"/\"+model_name):\n",
    "        print(\"Pickle file does exists...\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Pickle file does NOT exists...\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Titanic_data(file_name, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, file_name)\n",
    "    return pd.read_csv(csv_path)\n",
    "        \n",
    "    \n",
    "def get_Titanic_data(file_name, titanic_url=TITANIC_URL, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, file_name)\n",
    "    \n",
    "    print(\"Checking if directory exists...\")\n",
    "    if not os.path.isdir(titanic_path):\n",
    "        os.makedirs(titanic_path)\n",
    "        print(\"Creating directory\")\n",
    "    \n",
    "    else: \n",
    "        print(\"Directory exists\") \n",
    "            \n",
    "        if os.path.isfile(csv_path):\n",
    "            print(file_name + \" file does exists...\")\n",
    "            print(\"extracting \" + file_name)\n",
    "            \n",
    "            titanic = load_Titanic_data(file_name)\n",
    "            print(\"\\nSuccess!\")\n",
    "            return titanic\n",
    "        \n",
    "        else:\n",
    "            print(file_name + \" file doesn't exists...\")\n",
    "            print(\"Download .csv from Kaggle!\")\n",
    "\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if directory exists...\n",
      "Directory exists\n",
      "train.csv file does exists...\n",
      "extracting train.csv\n",
      "\n",
      "Success!\n",
      "Checking if directory exists...\n",
      "Directory exists\n",
      "test.csv file does exists...\n",
      "extracting test.csv\n",
      "\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "Train = get_Titanic_data(train_name)\n",
    "Test = get_Titanic_data(test_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "Train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variable - Definition                              - Key\n",
    "1. survival - Survival                                - 0/1 = No/Yes\n",
    "2. pclass   - Ticket class                            - 1,2,3 = 1st, 2nd, 3rd class\n",
    "3. sex      - Sex                                     - male, female\n",
    "4. Age      - Age in years                            - ...\n",
    "5. sibsp    - # of siblings/spouses on the Titanic    - ...\n",
    "6. parch    - # of parents/children on the Titanic    - ...\n",
    "7. ticket   - Ticket number                           - ...\n",
    "8. fare     - Passenger fare                          - ...\n",
    "9. cabin    - Cabin number                            - ...\n",
    "10. embarked - Port of Embarkation                     - C = Cherbourg, Q = Queenstown, S = Southampton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.38% Survived\n",
      "61.62% Died\n"
     ]
    }
   ],
   "source": [
    "sur = Train[\"Survived\"].value_counts() / len(Train)\n",
    "print(\"{:.2f}% Survived\\n{:.2f}% Died\".format(100*sur[1],100*sur[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       1.000000\n",
       "Fare           0.257307\n",
       "Parch          0.081629\n",
       "PassengerId   -0.005007\n",
       "SibSp         -0.035322\n",
       "Age           -0.077221\n",
       "Pclass        -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation matrix\n",
    "corr_matrix = Train.corr()\n",
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 712 entries, Verificaiton set: 179 entries\n"
     ]
    }
   ],
   "source": [
    "#Split \"Train\" into Training and Verification datasets\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=50)\n",
    "\n",
    "for train_index, ver_index in split.split(Train, Train[\"Survived\"]):\n",
    "    Train_strat = Train.loc[train_index]\n",
    "    Ver_strat = Train.loc[ver_index]\n",
    "\n",
    "print(\"Training set: {} entries, Verificaiton set: {} entries\".format(len(Train_strat),len(Ver_strat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separtate labels from features\n",
    "y_train = Train_strat[\"Survived\"].copy()\n",
    "X_train = Train_strat.drop(\"Survived\", axis=1)\n",
    "\n",
    "y_ver = Ver_strat[\"Survived\"].copy()\n",
    "X_ver = Ver_strat.drop(\"Survived\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Features (survived is already removed)\n",
    "list_drop = ['Name', 'Ticket', 'Cabin']\n",
    "\n",
    "Dropped = X_train[list(set(X_train.columns) - set(list_drop))]\n",
    "\n",
    "#Numeric Features\n",
    "list_num = Dropped.select_dtypes(include = [\"number\"]).columns\n",
    "\n",
    "#Catagorical Features (to be transformed into OHE)\n",
    "list_cat = Dropped.select_dtypes(include = [\"object\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return(self)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.feature_names].values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numeric Transformations\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', Selector(list_num)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "#Catagorical Transformations\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', Selector(list_cat)),\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perpare_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "X_tr = perpare_pipeline.fit_transform(X_train)\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 73.74%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_v = perpare_pipeline.fit_transform(X_ver)\n",
    "y_predict = sgd_clf.predict(X_v)\n",
    "\n",
    "acc = accuracy_score(y_ver, y_predict)\n",
    "print(\"Accuracy Score: {:.2f}%\\n\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Neg:  93\t\tFalse Pos: 17\n",
      "False Neg: 30\t\tTrue Pos:  39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con_m = confusion_matrix(y_ver, y_predict)\n",
    "\n",
    "print(\"True Neg:  {}\\t\\tFalse Pos: {}\\nFalse Neg: {}\\t\\tTrue Pos:  {}\\n\"\n",
    "      .format(con_m[0][0], con_m[0][1], con_m[1][0], con_m[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(con_m, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiers\n",
    "\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create new model if pickle already even if pickle exists; load_pkl = False\n",
    "load_pkl = True\n",
    "\n",
    "    \n",
    "#Linear Support Vector Classifier\n",
    "if pickle_exist(\"lin_clf\") and load_pkl:\n",
    "    lin_clf = load_pickle(\"lin_clf\")\n",
    "else:\n",
    "    lin_clf = LinearSVC(loss=\"hinge\", C=C, \n",
    "                        random_state=42)\n",
    "    lin_clf.fit(X_scaled, y_new)\n",
    "    save_pickle(\"lin_clf\", lin_clf)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#Support Vector Machine Classifier    \n",
    "if pickle_exist(\"svc_clf\") and load_pickle:\n",
    "    svc_clf = load_pickle(\"svc_clf\")\n",
    "else:\n",
    "    svc_clf = SVC(kernel=\"linear\",  C=C)\n",
    "    svc_clf.fit(X_scaled, y_new)\n",
    "    save_pickle(\"svc_clf\", svc_clf)\n",
    "    \n",
    "    \n",
    "\n",
    "#Stochastic Gradient Descent Classifier    \n",
    "if pickle_exist(\"sgd_clf\") and load_pickle:\n",
    "    sgd_clf = load_pickle(\"sgd_clf\")\n",
    "else:\n",
    "    sgd_clf = SGDClassifier(\n",
    "        loss=\"hinge\", alpha=1/(m*C), random_state=42)\n",
    "    sgd_clf.fit(X_scaled, y_new)\n",
    "    save_pickle(\"sgd_clf\", sgd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
